{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1b44b5a-f41b-4970-ba7a-ea2f2f2343fa",
   "metadata": {},
   "source": [
    "# Trabalho Final - Aprendizado por Reforço"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1babc680-d742-4145-98a4-06d1012e6dab",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?app=desktop&v=bD6V3rcr_54&t=0s\n",
    "\n",
    "https://www.jmlr.org/papers/v22/20-1364.html\n",
    "\n",
    "\n",
    "https://gymnasium.farama.org/introduction/create_custom_env/\n",
    "\n",
    "https://github.com/github0apurva/TabularData_Reinforcement\n",
    "\n",
    "https://github.com/github0apurva/TabularData_Reinforcement/tree/main\n",
    "\n",
    "https://stackoverflow.com/questions/58964267/how-to-create-an-openai-gym-observation-space-with-multiple-features\n",
    "\n",
    "https://docs.ray.io/en/master/rllib/index.html\n",
    "\n",
    "https://gymnasium.farama.org/api/spaces/utils/#gymnasium.spaces.utils.flatten_space\n",
    "\n",
    "\n",
    "**https://medium.com/@tom.kaminski01/reinforcement-learning-for-f9a28632914f**\n",
    "\n",
    "**https://gymnasium.farama.org/introduction/create_custom_env/**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0aef44a5-c946-4e85-865e-bd4579be64a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from stable_baselines3.dqn import MlpPolicy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common import monitor \n",
    "from stable_baselines3.common import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49937f9d-eb29-44b5-9e73-b949164309d4",
   "metadata": {},
   "source": [
    "### Separando os Conjuntos Teste x Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "92ee9130-20fe-4a54-a706-aec5668ec68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os dados do Excel\n",
    "df_dataset = pd.read_excel('./DadosGolfitSoccer_2024_07_03.xlsx')\n",
    "# Removendo colunas desnecessárias\n",
    "df_dataset.drop(columns=['Codigo', 'Ano_Avaliacao', 'Nome', 'CategoriaEtaria', 'Ano_Nascimento','CLUBE', 'PosicaoJogo', 'YOYO_Percurso'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fa66b0f2-e8ca-473c-a7b3-dbb05e44b5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IdadeDecimal</th>\n",
       "      <th>Sucesso</th>\n",
       "      <th>Quartil_Nascimento</th>\n",
       "      <th>Dominância</th>\n",
       "      <th>Ambidestro</th>\n",
       "      <th>IdadeInicio</th>\n",
       "      <th>NivelDISPUTA</th>\n",
       "      <th>NivelVIToRIA</th>\n",
       "      <th>AtletanaFamilia</th>\n",
       "      <th>TempoPratica_anos</th>\n",
       "      <th>...</th>\n",
       "      <th>ForcaPreensao</th>\n",
       "      <th>Flexibilidade</th>\n",
       "      <th>CMJ</th>\n",
       "      <th>Agilidade</th>\n",
       "      <th>Drible</th>\n",
       "      <th>DeltaDrible</th>\n",
       "      <th>Vel10m</th>\n",
       "      <th>Vel20m</th>\n",
       "      <th>AvaliacaoTreinador</th>\n",
       "      <th>Intangiveis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.658453</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.658453</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>7.525</td>\n",
       "      <td>10.560</td>\n",
       "      <td>3.035</td>\n",
       "      <td>1.891</td>\n",
       "      <td>3.296</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.913758</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.913758</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>37.6</td>\n",
       "      <td>7.559</td>\n",
       "      <td>10.276</td>\n",
       "      <td>2.717</td>\n",
       "      <td>1.874</td>\n",
       "      <td>3.213</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.928131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.928131</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>28.1</td>\n",
       "      <td>7.480</td>\n",
       "      <td>10.220</td>\n",
       "      <td>2.740</td>\n",
       "      <td>1.685</td>\n",
       "      <td>2.950</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.774127</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.774127</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.7</td>\n",
       "      <td>8.733</td>\n",
       "      <td>12.700</td>\n",
       "      <td>3.967</td>\n",
       "      <td>1.949</td>\n",
       "      <td>3.463</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.956194</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.956194</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>34.7</td>\n",
       "      <td>8.870</td>\n",
       "      <td>11.960</td>\n",
       "      <td>3.090</td>\n",
       "      <td>1.939</td>\n",
       "      <td>3.317</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>15.219713</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.219713</td>\n",
       "      <td>...</td>\n",
       "      <td>31.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>7.487</td>\n",
       "      <td>10.481</td>\n",
       "      <td>2.994</td>\n",
       "      <td>1.774</td>\n",
       "      <td>3.073</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>15.006160</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8.006160</td>\n",
       "      <td>...</td>\n",
       "      <td>38.1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.2</td>\n",
       "      <td>7.598</td>\n",
       "      <td>10.449</td>\n",
       "      <td>2.851</td>\n",
       "      <td>1.486</td>\n",
       "      <td>3.073</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>15.134839</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.134839</td>\n",
       "      <td>...</td>\n",
       "      <td>36.4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>36.1</td>\n",
       "      <td>8.043</td>\n",
       "      <td>11.118</td>\n",
       "      <td>3.075</td>\n",
       "      <td>1.641</td>\n",
       "      <td>2.689</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>16.183436</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.183436</td>\n",
       "      <td>...</td>\n",
       "      <td>24.4</td>\n",
       "      <td>19.2</td>\n",
       "      <td>36.4</td>\n",
       "      <td>6.988</td>\n",
       "      <td>9.641</td>\n",
       "      <td>2.653</td>\n",
       "      <td>1.640</td>\n",
       "      <td>2.913</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>13.834360</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.834360</td>\n",
       "      <td>...</td>\n",
       "      <td>37.3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>7.669</td>\n",
       "      <td>10.882</td>\n",
       "      <td>3.213</td>\n",
       "      <td>1.677</td>\n",
       "      <td>3.186</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     IdadeDecimal  Sucesso  Quartil_Nascimento  Dominância  Ambidestro  \\\n",
       "0       14.658453        0                   2           1           0   \n",
       "1       13.913758        0                   1           1           0   \n",
       "2       16.928131        0                   1           1           0   \n",
       "3       13.774127        0                   2           1           0   \n",
       "4       15.956194        0                   1           1           0   \n",
       "..            ...      ...                 ...         ...         ...   \n",
       "122     15.219713        0                   4           1           0   \n",
       "123     15.006160        0                   1           1           0   \n",
       "124     15.134839        0                   1           2           0   \n",
       "125     16.183436        0                   1           1           0   \n",
       "126     13.834360        0                   2           3           1   \n",
       "\n",
       "     IdadeInicio  NivelDISPUTA  NivelVIToRIA  AtletanaFamilia  \\\n",
       "0            8.0             2           1.0                0   \n",
       "1            4.0             3           3.0                0   \n",
       "2            4.0             4           0.0                1   \n",
       "3            6.0             1           1.0                0   \n",
       "4            6.0             1           1.0                1   \n",
       "..           ...           ...           ...              ...   \n",
       "122          9.0             2           2.0                0   \n",
       "123          7.0             0           NaN                0   \n",
       "124          9.0             2           2.0                1   \n",
       "125          7.0             2           2.0                1   \n",
       "126          9.0             3           1.0                0   \n",
       "\n",
       "     TempoPratica_anos  ...  ForcaPreensao  Flexibilidade   CMJ  Agilidade  \\\n",
       "0             6.658453  ...           22.0           27.0  35.9      7.525   \n",
       "1             9.913758  ...           25.0           17.5  37.6      7.559   \n",
       "2            12.928131  ...           38.0           21.5  28.1      7.480   \n",
       "3             7.774127  ...           14.0           26.0  26.7      8.733   \n",
       "4             9.956194  ...           32.0           35.5  34.7      8.870   \n",
       "..                 ...  ...            ...            ...   ...        ...   \n",
       "122           6.219713  ...           31.1           23.0  25.6      7.487   \n",
       "123           8.006160  ...           38.1           21.0  42.2      7.598   \n",
       "124           6.134839  ...           36.4           25.0  36.1      8.043   \n",
       "125           9.183436  ...           24.4           19.2  36.4      6.988   \n",
       "126           4.834360  ...           37.3           30.0  33.5      7.669   \n",
       "\n",
       "     Drible  DeltaDrible  Vel10m  Vel20m  AvaliacaoTreinador  Intangiveis  \n",
       "0    10.560        3.035   1.891   3.296                   3           31  \n",
       "1    10.276        2.717   1.874   3.213                   3           26  \n",
       "2    10.220        2.740   1.685   2.950                   5           38  \n",
       "3    12.700        3.967   1.949   3.463                   2           18  \n",
       "4    11.960        3.090   1.939   3.317                   4           34  \n",
       "..      ...          ...     ...     ...                 ...          ...  \n",
       "122  10.481        2.994   1.774   3.073                   3           35  \n",
       "123  10.449        2.851   1.486   3.073                   3           24  \n",
       "124  11.118        3.075   1.641   2.689                   2           32  \n",
       "125   9.641        2.653   1.640   2.913                   3           35  \n",
       "126  10.882        3.213   1.677   3.186                   4           41  \n",
       "\n",
       "[127 rows x 42 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a6534601-2fa2-4fca-ba53-578bd0eb43ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os conjuntos de teste e treino\n",
    "df_train, df_test = train_test_split(df_dataset, test_size=0.2)\n",
    "\n",
    "# Retirando a coluna da classe - Sucesso\n",
    "df_train_X = np.array(df_train.drop('Sucesso', axis=1))\n",
    "# Convertendo a coluna para o tipo que será usado pelo modelo\n",
    "df_train_y = np.array(df_train['Sucesso'])\n",
    "\n",
    "# Testar o uso das dimensões expandidas\n",
    "# df_train_X = np.expand_dims(df_train_X, 1)\n",
    "# df_train_y = np.expand_dims(df_train_y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "12a3f767-aba2-4dfb-83ce-ea111d936a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.81861739,  2.        ,  1.        , ...,  2.745     ,\n",
       "         2.        , 17.        ],\n",
       "       [17.00479124,  1.        ,  1.        , ...,  2.835     ,\n",
       "         4.        , 39.        ],\n",
       "       [13.79876797,  2.        ,  1.        , ...,         nan,\n",
       "         3.        , 25.        ],\n",
       "       ...,\n",
       "       [14.57905544,  3.        ,  1.        , ...,  3.188     ,\n",
       "         4.        , 45.        ],\n",
       "       [16.56947296,  3.        ,  2.        , ...,  3.057     ,\n",
       "         2.        , 23.        ],\n",
       "       [13.83436003,  2.        ,  3.        , ...,  3.186     ,\n",
       "         4.        , 41.        ]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d5d149dd-85e6-422d-a2ca-392910ccd66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd70dce7-9408-4f97-888b-add182604f47",
   "metadata": {},
   "source": [
    "### Criando o ambiente para classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "28841162-9b00-40ef-a958-cc383a8b993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando um ambiente a partir do ambiente fornecido pelo Gym\n",
    "class PlayersEnv(Env):\n",
    "    def __init__(self, majority_class=0, minority_class=1, row_per_episode=1, dataset=(df_train_X, df_train_y)):\n",
    "        # As ações que o agente podem tomar são discretas, envolvendo classificar entre 2 classes\n",
    "        self.action_space = Discrete(2)\n",
    "        \n",
    "        # O espaço de observações consiste nos jogadores que o agente deve classificar - 42 features para cada jogador\n",
    "        obersevation = np.array([[np.finfo('float32').max] * 42], dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(-obersevation, obersevation, shape=(1, 42), dtype=np.float32)\n",
    "\n",
    "        # Definindo qual as classe majoritária/minoritária do dataset - Para lidar com desbalanceamento dos dados\n",
    "        self.majority_class = majority_class\n",
    "        self.minority_class = minority_class\n",
    "\n",
    "        # self.observations_space = Box(low=0, high=1, shape=())\n",
    "        # Estado inicial em que o agente começa a interação\n",
    "        self.state = 0\n",
    "        # Tamanho do episódio == quantidade de instâncias (jogadores) a serem classificados\n",
    "        self.episode_length = 0\n",
    "\n",
    "        # Definição de parâmetros\n",
    "        self.row_per_episode = row_per_episode\n",
    "        self.step_count = 0\n",
    "        self.x, self.y = dataset\n",
    "        self.dataset_idx = 0\n",
    "        \n",
    "\n",
    "    # Função que especifica o que o agente fará a cada passo - Representa uma ação do agente\n",
    "    # Recebe a ação tomada pelo agente como parâmetro\n",
    "    def step(self, action):\n",
    "        # Verificar se o agente classificou certo\n",
    "        # Diferenciar recompensas para a classe maioritária e minoritária\n",
    "        # Utilizar a fórmula definida pelos autores na metodologia do artigo\n",
    "\n",
    "        # Flag que define se a tomada de decisão está finalizada\n",
    "        done = False\n",
    "\n",
    "        # Definição das recompensas caso o agente tome a decisão CORRETA\n",
    "        if action == self.expected_action:\n",
    "            match self.expected_action:\n",
    "                # Caso o atleta seja da classe majoritária recebe uma recompensa menor\n",
    "                case self.majority_class:\n",
    "                    reward = 1\n",
    "                # Caso o atleta seja da classe minoritária recebe uma recompensa maior\n",
    "                case self.minority_class:\n",
    "                    reward = 10\n",
    "\n",
    "        # Definição das recompensas caso o agente tome a decisão INCORRETA\n",
    "        if action != self.expected_action:\n",
    "            match self.expected_action:\n",
    "                # Caso o atleta seja da classe majoritária recebe uma recompensa menor\n",
    "                case self.majority_class:\n",
    "                    reward = -1\n",
    "                # Caso o atleta seja da classe minoritária recebe uma recompensa maior\n",
    "                case self.minority_class:\n",
    "                    reward = -10\n",
    "\n",
    "        # Passa para a próxima observação do dataset\n",
    "        observation = self._next_observation()\n",
    "\n",
    "        # Aumenta a contagem de decisões tomadas\n",
    "        self.step_count += 1\n",
    "\n",
    "        # Caso a quantidade de passos definidos por episódio tenha sido alcançada\n",
    "        if self.step_count >= self.row_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {}  \n",
    "\n",
    "    # Função que reseta o ambiente para treinar novamente\n",
    "    def reset(self):\n",
    "        # Zera a contagem de passos\n",
    "        self.step_count = 0\n",
    "        # Define a nova observação inicial\n",
    "        observation = self._next_observation()\n",
    "        # Retorna a observação inicial\n",
    "        return observation\n",
    "\n",
    "    # Subrotina que retorna a próxima observação para o agente\n",
    "    def _next_observation(self):\n",
    "        # Define um índice de forma aleatória para a próxima observação\n",
    "        next_observation_idx = random.randint(0, len(self.x) - 1)\n",
    "        # Define a ação esperada para a observação - Retorna o rótulo da observação\n",
    "        self.expected_action = int(self.y[next_observation_idx])\n",
    "        # Extrai a observação com o índice aleatório definido anteriormente\n",
    "        observation = self.x[next_observation_idx]\n",
    "\n",
    "        return observation\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a40388-8037-4cd6-b9ba-dc6182555d8a",
   "metadata": {},
   "source": [
    "### Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f137b795-c43c-4947-8eeb-ffd4404a0109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (41,) into shape (1,42)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 15\u001b[0m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m'\u001b[39m, environment,\n\u001b[0;32m     11\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Treinando o modelo\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# model.learn(total_timesteps=int(1.2e4))\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Medindo o tempo de treinamento\u001b[39;00m\n\u001b[0;32m     18\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:311\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    304\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    309\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:310\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfOnPolicyAlgorithm,\n\u001b[0;32m    301\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    307\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfOnPolicyAlgorithm:\n\u001b[0;32m    308\u001b[0m     iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 310\u001b[0m     total_timesteps, callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_learn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:423\u001b[0m, in \u001b[0;36mBaseAlgorithm._setup_learn\u001b[1;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset_num_timesteps \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_episode_starts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;66;03m# Retrieve unnormalized observation for saving into the buffer\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:78\u001b[0m, in \u001b[0;36mDummyVecEnv.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m     maybe_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptions\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[env_idx]} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[env_idx] \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m     77\u001b[0m     obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs[env_idx]\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds[env_idx], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmaybe_options)\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Seeds and options are only used once\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_seeds()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:108\u001b[0m, in \u001b[0;36mDummyVecEnv._save_obs\u001b[1;34m(self, env_idx, obs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 108\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuf_obs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m obs\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_obs[key][env_idx] \u001b[38;5;241m=\u001b[39m obs[key]\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (41,) into shape (1,42)"
     ]
    }
   ],
   "source": [
    "# Configurando a pasta para logs\n",
    "# logger.configure('./logs', ['stdout', 'tensorboard'])\n",
    "# Instanciando o ambiente para treinamento\n",
    "environment = PlayersEnv()\n",
    "# Encapsulando o ambiente para logs\n",
    "# environment = DummyVecEnv([lambda: monitor.Monitor(PlayersEnv(), logger.Logger('./logs',['stdout', 'tensorboard']).get_dir())])\n",
    "\n",
    "# Inicializando o modelo PPO\n",
    "model = PPO(\n",
    "    'MlpPolicy', environment,\n",
    "    verbose=1)\n",
    "\n",
    "# Treinando o modelo\n",
    "# model.learn(total_timesteps=int(1.2e4))\n",
    "model.learn(total_timesteps=int(100))\n",
    "\n",
    "# Medindo o tempo de treinamento\n",
    "start_time = time.time()\n",
    "print(\"Tempo de Treinamento PPO:\", time.time() - start_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".RL_env",
   "language": "python",
   "name": ".rl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
