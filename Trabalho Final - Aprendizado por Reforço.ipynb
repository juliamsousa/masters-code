{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1b44b5a-f41b-4970-ba7a-ea2f2f2343fa",
   "metadata": {},
   "source": [
    "# Trabalho Final - Aprendizado por Reforço"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b2135c-1206-417a-8c80-45a93f99074e",
   "metadata": {},
   "source": [
    "### Importando os pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0aef44a5-c946-4e85-865e-bd4579be64a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from stable_baselines3.dqn import MlpPolicy, MultiInputPolicy\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common import monitor \n",
    "from stable_baselines3.common import logger\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49937f9d-eb29-44b5-9e73-b949164309d4",
   "metadata": {},
   "source": [
    "### Separando os Conjuntos Teste x Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f3ae659c-ac61-42c7-9a43-2aabd4b22112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os dados do Excel\n",
    "df_dataset = pd.read_excel('./DadosGolfitSoccer_2024_07_03.xlsx')\n",
    "\n",
    "# Removendo colunas desnecessárias\n",
    "df_dataset.drop(columns=['Codigo', 'Ano_Avaliacao', 'Nome', 'CategoriaEtaria', 'Ano_Nascimento','CLUBE', 'PosicaoJogo'], inplace=True)\n",
    "\n",
    "# Removendo as linhas com valores vazios\n",
    "df_dataset.dropna(\n",
    "    axis=0,\n",
    "    how='any',\n",
    "    subset=None,\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Separando o conjunto de features\n",
    "X = df_dataset.drop('Sucesso', axis=1)\n",
    "# Separando o conjunto de rótulos\n",
    "y = df_dataset['Sucesso']\n",
    "\n",
    "# Separando os conjuntos de teste e treino\n",
    "# O parâmetro de estratificação é utilizado para balancear a quantidade das classes entre todas as divisões\n",
    "# O parâmetro random_state é utilizado como seed para a divisão dos conjuntos de teste e treino\n",
    "df_train_X, df_test_X, df_train_y, df_test_y = train_test_split(X, y, stratify=y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "\n",
    "# Retirando a coluna da classe - Sucesso\n",
    "df_train_X = np.array(df_train_X)\n",
    "# Convertendo a coluna para o tipo que será usado pelo modelo\n",
    "df_train_y = np.array(df_train_y)\n",
    "\n",
    "# Dataset - Teste\n",
    "# Retirando a coluna da classe - Sucesso\n",
    "df_test_X = np.array(df_test_X)\n",
    "# Convertendo a coluna para o tipo que será usado pelo modelo\n",
    "df_test_y = np.array(df_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b453b9f-a8c4-4078-9c39-ded3a7358da2",
   "metadata": {},
   "source": [
    "### Calculando a taxa de desbalanceamento entre as classes\n",
    "![taxa_desbalanceamento](./taxa_desbalanceamento.png)\n",
    "\n",
    "|DP|/|DN|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1092b855-9538-482d-bc0b-6352739c33af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET TREINO\n",
      "Quantidade de atletas da classe majoritária:  63\n",
      "Quantidade de atletas da classe minoritária:  14\n",
      "Taxa de desbalanceamento do DataSet:  0.2222222222222222\n",
      "\n",
      "DATASET TESTE\n",
      "Quantidade de atletas da classe majoritária:  27\n",
      "Quantidade de atletas da classe minoritária:  6\n",
      "Taxa de desbalanceamento do DataSet:  0.2222222222222222\n"
     ]
    }
   ],
   "source": [
    "# Calculando a quantidade de instâncias pertencentes à classe majoritária - DN\n",
    "quantity_DN = (df_train_y == 0).sum()\n",
    "# Calculando a quantidade de instâncias pertencentes à classe minoritária - DP\n",
    "quantity_DP = (df_train_y == 1).sum()\n",
    "# Calculando a taxa de desbalanceamento do DataSet\n",
    "calculated_imbalance_rate = quantity_DP/quantity_DN\n",
    "\n",
    "print(\"DATASET TREINO\")\n",
    "print(\"Quantidade de atletas da classe majoritária: \", quantity_DN)\n",
    "print(\"Quantidade de atletas da classe minoritária: \", quantity_DP)\n",
    "print(\"Taxa de desbalanceamento do DataSet: \", calculated_imbalance_rate)\n",
    "\n",
    "# Calculando a quantidade de instâncias pertencentes à classe majoritária - DN\n",
    "quantity_DN = (df_test_y == 0).sum()\n",
    "# Calculando a quantidade de instâncias pertencentes à classe minoritária - DP\n",
    "quantity_DP = (df_test_y == 1).sum()\n",
    "# Calculando a taxa de desbalanceamento do DataSet\n",
    "calculated_imbalance_rate = quantity_DP/quantity_DN\n",
    "\n",
    "print(\"\\nDATASET TESTE\")\n",
    "print(\"Quantidade de atletas da classe majoritária: \", quantity_DN)\n",
    "print(\"Quantidade de atletas da classe minoritária: \", quantity_DP)\n",
    "print(\"Taxa de desbalanceamento do DataSet: \", calculated_imbalance_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd70dce7-9408-4f97-888b-add182604f47",
   "metadata": {},
   "source": [
    "### Criando o ambiente para classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "28841162-9b00-40ef-a958-cc383a8b993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Env: uma classe python de alto-nível que representa um MDP(Processo de Decisão de Markov)\n",
    "#      permite ao usuário gerar o estado inicial, transição de estados e visualização do ambiente\n",
    "# Instanciando um ambiente a partir do ambiente fornecido pelo Gym\n",
    "class PlayersEnv(Env):\n",
    "    # def __init__(self, majority_class=0, minority_class=1, row_per_episode=1, dataset=(df_train_X, df_train_y), imbalance_rate=calculated_imbalance_rate):\n",
    "    def __init__(self, majority_class, minority_class, row_per_episode, dataset, imbalance_rate):\n",
    "        # As ações que o agente podem tomar são discretas, envolvendo classificar entre 2 classes\n",
    "        self.action_space = Discrete(2)\n",
    "        \n",
    "        # O espaço de observações consiste nos jogadores que o agente deve classificar - 42 features para cada jogador\n",
    "        # obersevation = np.array([[np.finfo('float32').max] * 42], dtype=np.float32)\n",
    "        self.observation_space = Box(0, 60, shape=(42,), dtype=np.float32)\n",
    "        # }, seed=42)\n",
    "        # self.observation_space = Box(-obersevation, obersevation, shape=(1, 42), dtype=np.float32)\n",
    "\n",
    "        # Definindo qual as classe majoritária/minoritária do dataset - Para lidar com desbalanceamento dos dados\n",
    "        self.majority_class = majority_class\n",
    "        self.minority_class = minority_class\n",
    "\n",
    "        # Definindo a taxa de desbalanceamento entre as classes majoritária e minoritária\n",
    "        self.imbalance_rate = imbalance_rate\n",
    "\n",
    "        # self.observations_space = Box(low=0, high=1, shape=())\n",
    "        # Estado inicial em que o agente começa a interação\n",
    "        self.state = 0\n",
    "        # Tamanho do episódio == quantidade de instâncias (jogadores) a serem classificados\n",
    "        self.episode_length = 0\n",
    "\n",
    "        ## Armazenamento de métricas\n",
    "        # Verdadeiro Positivo\n",
    "        self.TP = 0\n",
    "        # Falso Positivo\n",
    "        self.FP = 0\n",
    "        # Verdadeiro Negativo\n",
    "        self.TN = 0\n",
    "        # Falso Negativo\n",
    "        self.FN = 0\n",
    "        \n",
    "\n",
    "        # Definição de parâmetros\n",
    "        self.row_per_episode = row_per_episode\n",
    "        self.step_count = 0\n",
    "        self.x, self.y = dataset\n",
    "        self.dataset_idx = 0\n",
    "        \n",
    "\n",
    "    # Função que especifica o que o agente fará a cada passo - Representa uma ação do agente\n",
    "    # Recebe a ação tomada pelo agente como parâmetro\n",
    "    def step(self, action):\n",
    "        # Verificar se o agente classificou certo\n",
    "        # Diferenciar recompensas para a classe maioritária e minoritária\n",
    "        # Utilizar a fórmula definida pelos autores na metodologia do artigo\n",
    "\n",
    "        # Flag que define se a tomada de decisão está finalizada\n",
    "        done = False\n",
    "    \n",
    "        # Definição das recompensas caso o agente tome a decisão CORRETA\n",
    "        if action == self.expected_action:\n",
    "            match self.expected_action:\n",
    "                # Caso o atleta seja da classe majoritária recebe uma recompensa menor\n",
    "                case self.majority_class:\n",
    "                    # Retorna a recompensa pela ação\n",
    "                    reward = self.imbalance_rate * 1\n",
    "                    # Incrementa os Verdadeiros Negativos (TN)\n",
    "                    self.TN += 1\n",
    "                # Caso o atleta seja da classe minoritária recebe uma recompensa maior\n",
    "                case self.minority_class:\n",
    "                    # Retorna a recompensa pela ação\n",
    "                    reward = 1\n",
    "                    # Incrementa os Verdadeiros Positivos (TP)\n",
    "                    self.TP += 1\n",
    "\n",
    "        # Definição das recompensas caso o agente tome a decisão INCORRETA\n",
    "        if action != self.expected_action:\n",
    "            match self.expected_action:\n",
    "                # Caso o atleta seja da classe majoritária recebe uma recompensa menor\n",
    "                case self.majority_class:\n",
    "                    # Retorna a recompensa pela ação\n",
    "                    reward = self.imbalance_rate * -1\n",
    "                    # Incrementa os Falso Negativos (FN)\n",
    "                    self.FP += 1\n",
    "                # Caso o atleta seja da classe minoritária recebe uma recompensa maior\n",
    "                case self.minority_class:\n",
    "                    # Retorna a recompensa pela ação\n",
    "                    reward = -1\n",
    "                    # Incrementa os Verdadeiros Negativos (TN)\n",
    "                    self.FN += 1\n",
    "\n",
    "        # Passa para a próxima observação do dataset\n",
    "        observation = self._next_observation()\n",
    "\n",
    "        # Aumenta a contagem de decisões tomadas\n",
    "        self.step_count += 1\n",
    "\n",
    "        # Caso a quantidade de passos definidos por episódio tenha sido alcançada\n",
    "        if self.step_count >= self.row_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return observation, reward, done, {}  \n",
    "\n",
    "    # Função que reseta o ambiente para treinar novamente\n",
    "    def reset(self):\n",
    "        # Zera a contagem de passos\n",
    "        self.step_count = 0\n",
    "        # Define a nova observação inicial\n",
    "        observation = self._next_observation()\n",
    "        # Retorna a observação inicial\n",
    "        return observation\n",
    "\n",
    "    # Subrotina que retorna a próxima observação para o agente\n",
    "    def _next_observation(self):\n",
    "        # Define um índice de forma aleatória para a próxima observação\n",
    "        next_observation_idx = random.randint(0, len(self.x) - 1)\n",
    "        # Define a ação esperada para a observação - Retorna o rótulo da observação\n",
    "        self.expected_action = int(self.y[next_observation_idx])\n",
    "        # Extrai a observação com o índice aleatório definido anteriormente\n",
    "        observation = self.x[next_observation_idx]\n",
    "\n",
    "        return observation\n",
    "\n",
    "    # Subrotina que calcula as métricas do modelo\n",
    "    def metrics(self):\n",
    "        TPrate = self.TP / (self.TP + self.FN) \n",
    "        TNrate = self.TN / (self.TN + self.FP)\n",
    "        FPrate = self.FP / (self.TN + self.FP)\n",
    "        FNrate = self.FN / (self.TP + self.FN)\n",
    "        PPvalue = self.TP / (self.TP + self.FP)\n",
    "        NPvalue = self.TN / (self.TN + self.FN)\n",
    "\n",
    "        G_mean = np.sqrt(TPrate * TNrate)\n",
    "\n",
    "        Recall = TPrate = self.TP / (self.TP + self.FN)\n",
    "        Precision = PPvalue = self.TP / (self.TP + self.FP)\n",
    "        F_measure = 2 * Recall * Precision / (Recall + Precision)\n",
    " \n",
    "        return TPrate, TNrate, G_mean, F_measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a40388-8037-4cd6-b9ba-dc6182555d8a",
   "metadata": {},
   "source": [
    "### Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f137b795-c43c-4947-8eeb-ffd4404a0109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Instanciando o ambiente para treinamento\n",
    "environment = PlayersEnv(\n",
    "    majority_class=0, \n",
    "    minority_class=1, \n",
    "    row_per_episode=1, \n",
    "    dataset=(df_train_X, df_train_y), \n",
    "    imbalance_rate=calculated_imbalance_rate\n",
    ")\n",
    "\n",
    "environment.observation_space.shape\n",
    "\n",
    "# Inicializando o modelo DQN\n",
    "model = DQN(\n",
    "    \"MlpPolicy\", \n",
    "    DummyVecEnv([lambda: environment]), \n",
    "    learning_rate=0.001, \n",
    "    gamma=0.99\n",
    ")\n",
    "\n",
    "# Treinando o modelo\n",
    "model.learn(total_timesteps=77)\n",
    "\n",
    "# Salvando o modelo para validação\n",
    "model.save(\"IC_MDP_DQN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1df6b2-3952-46ce-81e6-951c5377a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No modelo DQNIMB In DQNimb model, a recompensa para a classe minoritária é 1 e para a clase majoritária é λ\n",
    "# Testar diferentes valores de lambda λ\n",
    "# {0.05ρ, 0.1ρ, 0.5ρ, ρ, 5ρ, 10ρ, 20ρ}."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e04690a-2248-4184-819d-2d63b9f9ee02",
   "metadata": {},
   "source": [
    "### Validando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d9b3eb9b-b5cd-4cba-9782-98040450ba02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4666666666666667, 0.47692307692307695, 0.47176700029156615, 0.25)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Instanciando o ambiente para teste\n",
    "test_environment = PlayersEnv(\n",
    "    majority_class=0, \n",
    "    minority_class=1, \n",
    "    row_per_episode=1, \n",
    "    dataset=(df_test_X, df_test_y), \n",
    "    imbalance_rate=calculated_imbalance_rate\n",
    ")\n",
    "\n",
    "# Carregando o modelo treinado anteriormente\n",
    "model = DQN.load(\"IC_MDP_DQN\", env=DummyVecEnv([lambda: test_environment]))\n",
    "\n",
    "# Define a observação inicial\n",
    "test_environment = model.get_env()\n",
    "observation = test_environment.reset()\n",
    "\n",
    "# Percorre o DataSet de teste\n",
    "for i in range(33):\n",
    "    # Faz uma previsão com o modelo\n",
    "    action, done = model.predict(observation)\n",
    "    # Retorna a próxima observação\n",
    "    observation = test_environment.reset()\n",
    "\n",
    "\n",
    "# Imprimindo as métricas do modelo\n",
    "sensitivity, specificity, g_mean_metric, f_measure_metric = environment.metrics()\n",
    "\n",
    "# print(\"Sensibilidade (Recall/ Taxa de verdadeiros positivos): \", TPrate)\n",
    "# print(\"Especificidade (Taxa de verdadeiros negativos): \", TNrate)\n",
    "# print(\"Sensibilidade (Recall): \", TPrate)\n",
    "# print(\"Sensibilidade (Recall): \", TPrate)\n",
    "# print(\"Sensibilidade (Recall): \", TPrate)\n",
    "# print(\"Sensibilidade (Recall): \", TPrate)\n",
    "\n",
    "sensitivity, specificity, g_mean_metric, f_measure_metric"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".RL_env",
   "language": "python",
   "name": ".rl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
